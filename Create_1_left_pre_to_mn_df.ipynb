{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import utils\n",
    "import connectome_create\n",
    "# viz_method = one of ['itkwidgets', 'vtk']\n",
    "viz_method = 'vtk'\n",
    "\n",
    "# import some of our favorite packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "%matplotlib inline\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import nglui.statebuilder as ngstbld\n",
    "\n",
    "# this is the EM specific package for querying the EM data\n",
    "from caveclient import CAVEclient\n",
    "\n",
    "\n",
    "from meshparty import trimesh_io, trimesh_vtk\n",
    "from meshparty import skeletonize, skeleton_io, skeleton\n",
    "import cloudvolume\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# client = CAVEclient()\n",
    "\n",
    "# # if not os.path.isfile(os.path.expanduser(\"~/.cloudvolume/secrets/cave-secret.json\")):\n",
    "# client.auth.get_new_token(open=True)\n",
    "# # # if you have not yet setup this computer, uncomment this below line\n",
    "# # # paste the token from the website in, and run the line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.auth.save_token(token=\"fca0294ed408d104e0eebe74514c744b\", overwrite=True)\n",
    "\n",
    "# # # then comment or delete the line as you don't need to run it on this computer  again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datastack_name = 'fanc_production_mar2021'\n",
    "\n",
    "client = CAVEclient(datastack_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.materialize.get_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.materialize.get_versions()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the pre_to_mn_df \n",
    "with index (segID,has_soma,sensory,neck,local) \n",
    "x \n",
    "(side, nerve,segment,function,muscle,rank,segID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_to_mn_df = connectome_create.left_pre_to_mn_df(client)\n",
    "#pre_to_mn_df = connectome_create.load_pre_to_mn_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_to_mn_df.loc[pre_to_mn_df.pre_pt_root_id==648518346489965495]\n",
    "(pre_to_mn_df.index.get_level_values('segID').to_numpy()==648518346489965495).any()\n",
    "# Ha, not there anymore!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "ts = dt.datetime.utctimetuple(dt.datetime.utcnow())\n",
    "my_tup = ts[0:3]\n",
    "type(my_tup)\n",
    "my_tup\n",
    "dt.datetime(ts[0],ts[1],ts[2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spot check some cells in the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_df = pre_to_mn_df.index.to_frame()\n",
    "# # idx_df.loc[648518346515671370]  # should now have a soma\n",
    "# # idx_df.loc[648518346509933350]  # should now have a soma\n",
    "# idx_df.loc[648518346492640443]  # should now have a soma\n",
    "# idx_df.loc[648518346514142507]  # should now have a soma\n",
    "# idx_df.loc[648518346494279701]  # should now have a soma\n",
    "# # All of the cells with bad somas are now in the soma table, 5/24/22\n",
    "idx_df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update the status of some fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now find some segids from points\n",
    "\n",
    "frags = pd.read_csv('~/Code/connectomics/connectomics/annotations_fragments/fragment_point_list_20220524.csv')\n",
    "frags = frags.rename(columns={'cell body position, other notes':'note'})\n",
    "\n",
    "frags_pt_series = frags['pt_position']\n",
    "frags_pt_ndarray = np.ndarray([len(frags_pt_series),3])\n",
    "\n",
    "pt_ints = []\n",
    "for rw in range(len(frags_pt_series)):\n",
    "    #print(i)\n",
    "    i = frags_pt_series[rw]\n",
    "    i = i.split('(')[0]\n",
    "    i = i.split(')')[0].split(', ')    \n",
    "    i = np.array([j for j in i if j != ''])\n",
    "    pt_ints.append(list(map(int, i)))\n",
    "    frags_pt_ndarray[rw,:] = i\n",
    "\n",
    "# frags_pt_ndarray = frags_pt_ndarray.astype(int)\n",
    "\n",
    "# Find segIDs from points\n",
    "cv = cloudvolume.CloudVolume(client.info.get_datastack_info()['segmentation_source'], use_https=True)\n",
    "segIDs = utils.segIDs_from_pts_service(frags_pt_ndarray,cv)\n",
    "frags['pt_root_id'] = segIDs\n",
    "frags = frags[['pt_position','pt_root_id','index_logical']]\n",
    "utils.save_df_as_pickle(frags,'frag_df')\n",
    "\n",
    "# idx_df.loc[648518346515671370]  # should now have a soma\n",
    "# All of the cells with bad somas are now in the soma table\n",
    "All = slice(None)\n",
    "print('There are {} cells with somas and {} sensory cells'.format(\n",
    "    idx_df.loc[(All,False,False,False,False,False),'has_soma'].sum(),\n",
    "    idx_df.loc[(All,False,False,False,False,False),'sensory'].sum()))\n",
    "\n",
    "for idx,row in frags.iterrows():\n",
    "    if row.index_logical == 'has_soma':\n",
    "        try:\n",
    "            idx_df.loc[(row.pt_root_id,All,All,All,All,All),'has_soma'] = True\n",
    "        except KeyError:\n",
    "            print('{} is no longer a fragment'.format(row.pt_root_id))\n",
    "        # print(idx_df.loc[row.pt_root_id,'has_soma'])\n",
    "    elif row.index_logical == 'sensory':\n",
    "        idx_df.loc[(row.pt_root_id,All,All,All,All,All),'sensory'] = True\n",
    "        # print(idx_df.loc[row.pt_root_id,'sensory'])\n",
    "\n",
    "print('There are now {} cells with somas and {} sensory cells'.format(\n",
    "    idx_df.loc[(All,False,False,False,False,False),'has_soma'].sum(),\n",
    "    idx_df.loc[(All,False,False,False,False,False),'sensory'].sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(segIDs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frags.pt_root_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_to_mn_df.index = pd.MultiIndex.from_frame(idx_df)\n",
    "connectome_create.save_pre_to_mn_df(pre_to_mn_df,ext='edited')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_to_mn_df2 = connectome_create.load_pre_to_mn_df(ext='edited')\n",
    "print(type(pre_to_mn_df2))\n",
    "pre_to_mn_df2.loc[(row.pt_root_id,False,True,False,False,False),:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All = slice(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many motor neurons are presynaptic to motor neurons\n",
    "# segID\tmotor\thas_soma\tsensory\t neck\tlocal\t\n",
    "motor = pre_to_mn_df.loc[(All,True,True,False,False,False),:]\n",
    "# descending.index.get_level_values('segID').to_list()\n",
    "motor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many sensory neurons # \n",
    "# segID\tmotor\thas_soma\tsensory\t neck\tlocal\t\n",
    "sensory = pre_to_mn_df.loc[(All,False,False,True,False,False),:]\n",
    "# descending.index.get_level_values('segID').to_list()\n",
    "sensory.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many weird neurons # \n",
    "# segID\tmotor\thas_soma\tsensory\t neck\tlocal\t\n",
    "weird = pre_to_mn_df.loc[(All,False,True,True,False,False),:]\n",
    "# descending.index.get_level_values('segID').to_list()\n",
    "weird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many descending neurons # 217\n",
    "# segID\tmotor\thas_soma\tsensory\t neck\tlocal\t\n",
    "descending = pre_to_mn_df.loc[(All,False,False,False,True),:]\n",
    "# descending.index.get_level_values('segID').to_list()\n",
    "descending.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many motor neurons are presynaptic to motor neurons\n",
    "# segID\tmotor\thas_soma\tsensory\t neck\tlocal\t\n",
    "ascending = pre_to_mn_df.loc[(All,False,True,False,True,False),:]\n",
    "# descending.index.get_level_values('segID').to_list()\n",
    "ascending.head()\n",
    "# some ascending that should be ascending\n",
    "# 648518346507084872\n",
    "# 648518346480786912\n",
    "# 648518346490374748\n",
    "sid = 648518346504729203\n",
    "ascending.index.get_level_values('segID')==sid\n",
    "# All are here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fragments?\n",
    "# segID\tmotor\thas_soma\tsensory\t neck\tlocal\t\n",
    "fragments = pre_to_mn_df.loc[(All,False,False,False,False,False),:]\n",
    "# descending.index.get_level_values('segID').to_list()\n",
    "fragments.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local and intersegmental?\n",
    "# segID\tmotor\thas_soma\tsensory\t neck\tlocal\t\n",
    "vncns = pre_to_mn_df.loc[(All,False,True,False,False,False),:]\n",
    "# descending.index.get_level_values('segID').to_list()\n",
    "vncns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look for suspicious ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "2b93c3ce0f0b01938714f8d6ce3882059af39419bb08f14e121c5729b1321faa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
